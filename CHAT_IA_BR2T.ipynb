{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmCYvfwa9dUvu0CmUT9ytK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mukabony/Calculadora-Meta-Venda/blob/main/CHAT_IA_BR2T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CHAT IA BR2T**"
      ],
      "metadata": {
        "id": "IsWz0krxmQlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Primeira C√©lula - Instala√ß√£o de Depend√™ncias üì¶ ‚úÖ (Validado)\n"
      ],
      "metadata": {
        "id": "WBLBgP3ve0sk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CfoooBFidEn1",
        "outputId": "f46b3466-57e4-4eda-a223-3b1570dda29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.4)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.59.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai pandas langchain-community langchain_openai pydantic langgraph requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##C√©lula 2 - Importa√ß√£o de Bibliotecas üìö ‚úÖ (Validado)\n"
      ],
      "metadata": {
        "id": "oZG_usNPhuBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from typing import TypedDict, Annotated, Sequence, Dict, List\n",
        "from pydantic import BaseModel\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import requests\n",
        "import json\n",
        "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "2IiRALbvhxvF"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##C√©lula 3 - Configura√ß√£o de APIs e Modelos üîë ‚úÖ (Validado)\n"
      ],
      "metadata": {
        "id": "q3xp0jV6fZnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura√ß√£o segura das chaves usando o sistema de secrets do Colab\n",
        "os.environ['DEEPSEEK_API_KEY'] = userdata.get('DEEPSEEK_API_KEY')\n",
        "os.environ['MILVUS_KEY'] = userdata.get('MILVUS_KEY')\n",
        "\n",
        "# Defini√ß√£o da URL base da API Milvus\n",
        "MILVUS_BASE_URL = \"https://apiintegracao.milvus.com.br/api\"\n",
        "\n",
        "# Configura√ß√£o do modelo DeepSeek (exemplo)\n",
        "llm_deepseek = ChatOpenAI(\n",
        "    model=\"deepseek-coder\",\n",
        "    temperature=0,\n",
        "    openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
        "    openai_api_base=\"https://api.deepseek.com/v1\"\n",
        ")\n",
        "\n",
        "# Verifica√ß√£o de configura√ß√£o\n",
        "def verify_api_keys():\n",
        "    required_keys = ['DEEPSEEK_API_KEY', 'MILVUS_KEY']\n",
        "    missing_keys = [key for key in required_keys if not userdata.get(key)]\n",
        "    if missing_keys:\n",
        "        print(\"\\n‚ö† Aten√ß√£o! As seguintes chaves est√£o faltando:\")\n",
        "        for key in missing_keys:\n",
        "            print(f\"- {key}\")\n",
        "        print(\"\\nPor favor, adicione-as no gerenciador de secrets do Colab!\")\n",
        "        return False\n",
        "    print(\"\\n‚úÖ Todas as chaves configuradas com sucesso!\")\n",
        "    return True\n",
        "\n",
        "verify_api_keys()\n",
        "\n",
        "llm = llm_deepseek\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_XL6p6cfsUQ",
        "outputId": "08e21f22-4d61-46b1-dca7-04ae81ed2df5"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Todas as chaves configuradas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##C√©lula 4 - Agente de Autentica√ß√£o üîê ‚úÖ (Validado)\n"
      ],
      "metadata": {
        "id": "y2LeAIARiDgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], \"Mensagens da conversa\"]\n",
        "    profile: Annotated[Dict, \"Informa√ß√µes do perfil do usu√°rio\"]\n",
        "    validation_result: Annotated[bool | None, \"Resultado da valida√ß√£o\"]\n",
        "    validation_details: Annotated[Dict, \"Detalhes da valida√ß√£o\"]\n",
        "    token_cliente: Annotated[str | None, \"Token do cliente para uso posterior\"]\n",
        "\n",
        "class MilvusAPI:\n",
        "    def __init__(self):\n",
        "        self.base_url = MILVUS_BASE_URL\n",
        "        self.headers = {\n",
        "            \"Authorization\": os.getenv('MILVUS_KEY'),\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def validate_tecnico(self, email: str) -> bool:\n",
        "        \"\"\"Valida t√©cnico verificando se existe algum chamado associado\"\"\"\n",
        "        url = f\"{self.base_url}/chamado/listagem\"\n",
        "        payload = {\n",
        "            \"filtro_body\": {\n",
        "                \"email_tecnico\": email\n",
        "            },\n",
        "            \"total_registros\": 1\n",
        "        }\n",
        "        try:\n",
        "            response = requests.post(url, headers=self.headers, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                return len(data.get(\"lista\", [])) > 0\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na valida√ß√£o do t√©cnico: {e}\")\n",
        "            return False\n",
        "\n",
        "    def validate_usuario(self, email: str) -> bool:\n",
        "        \"\"\"Valida usu√°rio cliente\"\"\"\n",
        "        url = f\"{self.base_url}/usuario-cliente/listar\"\n",
        "        payload = {\n",
        "            \"filtro_body\": {\n",
        "                \"email\": email,\n",
        "                \"status\": \"\"\n",
        "            },\n",
        "            \"total_registros\": 1,\n",
        "            \"pagina\": 1\n",
        "        }\n",
        "        try:\n",
        "            response = requests.post(url, headers=self.headers, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                return len(data.get(\"lista\", [])) > 0\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na valida√ß√£o do usu√°rio: {e}\")\n",
        "            return False\n",
        "\n",
        "    def validate_gestor(self, cnpj: str, state: AgentState) -> bool:\n",
        "        \"\"\"Valida gestor atrav√©s do CNPJ da empresa e obt√©m o token do cliente\"\"\"\n",
        "        url = f\"{self.base_url}/cliente/busca\"\n",
        "        params = {\"documento\": cnpj}\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if \"lista\" in data and len(data[\"lista\"]) > 0:\n",
        "                    state[\"token_cliente\"] = data[\"lista\"][0][\"token\"]\n",
        "                    return True\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na valida√ß√£o do gestor: {e}\")\n",
        "            return False\n",
        "\n",
        "    def listar_chamados(self, filtro_body: Dict) -> Dict:\n",
        "        \"\"\"Lista os chamados com base no filtro fornecido\"\"\"\n",
        "        url = f\"{self.base_url}/chamado/listagem\"\n",
        "        payload = {\n",
        "            \"filtro_body\": filtro_body,\n",
        "            \"total_registros\": 1000\n",
        "        }\n",
        "        try:\n",
        "            response = requests.post(url, headers=self.headers, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                return {\"erro\": f\"Erro na API: {response.status_code} - {response.text}\"}\n",
        "        except Exception as e:\n",
        "            return {\"erro\": f\"Exce√ß√£o ao chamar a API: {str(e)}\"}\n",
        "\n",
        "# Inst√¢ncia da API Milvus\n",
        "milvus_api = MilvusAPI()\n",
        "\n",
        "# Perfis v√°lidos com valida√ß√£o real\n",
        "VALID_PROFILES = {\n",
        "    \"master\": {\n",
        "        \"type\": \"master\",\n",
        "        \"validation\": lambda x, state: x.get(\"value\") == \"br2t\"\n",
        "    },\n",
        "    \"tecnico\": {\n",
        "        \"type\": \"tecnico\",\n",
        "        \"validation\": lambda x, state: milvus_api.validate_tecnico(x.get(\"value\"))\n",
        "    },\n",
        "    \"usuario\": {\n",
        "        \"type\": \"usuario\",\n",
        "        \"validation\": lambda x, state: milvus_api.validate_usuario(x.get(\"value\"))\n",
        "    },\n",
        "    \"gestor\": {\n",
        "        \"type\": \"gestor\",\n",
        "        \"validation\": lambda x, state: milvus_api.validate_gestor(x.get(\"value\"), state)\n",
        "    }\n",
        "}\n",
        "\n",
        "def validate_profile(state: AgentState) -> AgentState:\n",
        "    \"\"\"Fun√ß√£o de valida√ß√£o com integra√ß√£o real √† API Milvus\"\"\"\n",
        "    profile_data = state[\"profile\"]\n",
        "    profile_type = profile_data.get(\"profile\")\n",
        "\n",
        "    validation_details = {\n",
        "        \"profile_type\": profile_type,\n",
        "        \"validation_steps\": [],\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    if profile_type not in VALID_PROFILES:\n",
        "        validation_details[\"errors\"].append(f\"Tipo de perfil '{profile_type}' inv√°lido\")\n",
        "        state[\"validation_result\"] = False\n",
        "        state[\"validation_details\"] = validation_details\n",
        "        return state\n",
        "\n",
        "    profile_config = VALID_PROFILES[profile_type]\n",
        "    try:\n",
        "        validation_result = profile_config[\"validation\"](profile_data, state)\n",
        "        validation_details[\"validation_steps\"].append({\n",
        "            \"step\": \"api_validation\",\n",
        "            \"passed\": validation_result,\n",
        "            \"profile\": profile_type,\n",
        "            \"value\": profile_data.get(\"value\")\n",
        "        })\n",
        "        state[\"validation_result\"] = validation_result\n",
        "    except Exception as e:\n",
        "        validation_details[\"errors\"].append(f\"Erro na valida√ß√£o: {str(e)}\")\n",
        "        state[\"validation_result\"] = False\n",
        "\n",
        "    state[\"validation_details\"] = validation_details\n",
        "    return state\n",
        "\n",
        "# Configura√ß√£o do grafo\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"validate\", validate_profile)\n",
        "workflow.set_entry_point(\"validate\")\n",
        "workflow.add_edge(\"validate\", END)\n",
        "\n",
        "# Compila√ß√£o do grafo\n",
        "validation_graph = workflow.compile()\n"
      ],
      "metadata": {
        "id": "Fr1fhJ18iLOM"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üóíÔ∏è C√©lula 5 - Dicion√°rio da Documenta√ß√£o da API\n"
      ],
      "metadata": {
        "id": "WEZGIvDh1IY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_documentation = \"\"\"\n",
        "listagemChamados - listagemChamados\n",
        "Listagem de chamados\n",
        "POST https://apiintegracao.milvus.com.br/api/chamado/listagem\n",
        "Headers:\n",
        " - Authorization: Obrigat√≥rio o uso do token de autentica√ß√£o.\n",
        "Par√¢metros:\n",
        " - is_descending (boolean, opcional)\n",
        " - order_by (string, opcional)\n",
        " - total_registros (integer, opcional)\n",
        " - pagina (integer, opcional)\n",
        "\n",
        "Request Body Exemplo:\n",
        "\n",
        "  \"filtro_body\":\n",
        "    \"categoria_primaria\": \"SANKHYA\",\n",
        "    \"categoria_secundaria\": \"CONTROLAR OS OPERACIONAL SEM CUSTO\",\n",
        "    \"email_tecnico\": \"rjoins@br2t.com.br\",\n",
        "    ...\n",
        "\n",
        "\n",
        "\n",
        "Op√ß√µes de filtro 'status':\n",
        " 1 ou \"AgAtendimento\"\n",
        " 2 ou \"Atendendo\"\n",
        " 3 ou \"Pausado\"\n",
        " 4 ou \"Finalizado\"\n",
        " 5 ou \"Conferencia\"\n",
        " 6 ou \"Agendado\"\n",
        " 7 ou \"Expirado\"\n",
        " 9 ou \"ChamadosAbertos\"\n",
        "10 ou \"Todos\"\n",
        "11 ou \"AgSolucao\"\n",
        "13 ou \"AbertosNaoAgendados\"\n",
        "14 ou \"SemTecnico\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qzNV3VE-1OmS"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C√©lula 6 - Novo Dicion√°rio de Perguntas Pr√©-Definidas por Perfil**"
      ],
      "metadata": {
        "id": "ReipZy6jvlOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perguntas_padrao_profile = {\n",
        "    \"master\": [\n",
        "        {\n",
        "            \"pergunta\": \"Quantos chamados foram abertos na √∫ltima semana, separados por cada cliente?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"data_inicio\": \"2025-01-03\",\n",
        "                \"data_fim\": \"2025-01-10\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quais clientes t√™m mais chamados cr√≠ticos em aberto?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"ChamadosAbertos\",\n",
        "                \"prioridade\": \"Cr√≠tico\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Gostaria de ver a lista de chamados atrasados (SLA estourado) para todos os clientes.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"sla_resposta\": \"Estourado\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quero um relat√≥rio de quantos chamados cada t√©cnico fechou neste m√™s, por empresa.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Finalizado\",\n",
        "                \"data_inicio\": \"2025-01-01\",\n",
        "                \"data_fim\": \"2025-01-31\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Liste todos os chamados com prioridade m√©dia e alto impacto, preciso analisar a urg√™ncia do suporte.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"prioridade\": \"M√©dio\",\n",
        "                \"impacto\": \"Alto\"\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"usuario\": [\n",
        "        {\n",
        "            \"pergunta\": \"Quais chamados eu tenho em aberto agora?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"ChamadosAbertos\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Mostre meus chamados finalizados nos √∫ltimos 30 dias, por favor.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Finalizado\",\n",
        "                \"data_inicio\": \"2025-01-10\",\n",
        "                \"data_fim\": \"2025-02-09\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Preciso ver meu hist√≥rico de chamados sobre erro paytrack e configura√ß√µes, para comparar.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"assunto\": \"backup\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quero saber quais chamados est√£o com SLA estourado, pois ainda n√£o fui atendido.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"A fazer\",\n",
        "                \"sla_resposta\": \"Estourado\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Liste meus chamados com prioridade alta e me informe se j√° foram respondidos.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"prioridade\": \"Alto\"\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"gestor\": [\n",
        "        {\n",
        "            \"pergunta\": \"Quantos chamados meus usu√°rios abriram este m√™s?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"data_inicio\": \"2025-01-01\",\n",
        "                \"data_fim\": \"2025-01-31\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Liste todos os chamados cr√≠ticos que est√£o em aberto na minha empresa.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"ChamadosAbertos\",\n",
        "                \"prioridade\": \"Cr√≠tico\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quero verificar chamados finalizados sobre backup para saber se est√° tudo certo.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Finalizado\",\n",
        "                \"assunto\": \"backup\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quais chamados est√£o com SLA de resposta estourado, preciso acompanhar.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"sla_resposta\": \"Estourado\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Me mostre todos os chamados preventivos abertos hoje na minha empresa.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"A fazer\",\n",
        "                \"tipo_ticket\": \"Preventivo\",\n",
        "                \"data_inicio\": \"2025-01-10\",\n",
        "                \"data_fim\": \"2025-01-10\"\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"tecnico\": [\n",
        "        {\n",
        "            \"pergunta\": \"Quais chamados est√£o atribu√≠dos a mim e ainda n√£o foram solucionados?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"A fazer\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Preciso ver meus chamados finalizados neste m√™s, para acompanhar minhas horas.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Finalizado\",\n",
        "                \"data_inicio\": \"2025-01-01\",\n",
        "                \"data_fim\": \"2025-01-31\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Qual a lista de chamados preventivos que estou respons√°vel hoje?\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"A fazer\",\n",
        "                \"tipo_ticket\": \"Preventivo\",\n",
        "                \"data_inicio\": \"2025-01-10\",\n",
        "                \"data_fim\": \"2025-01-10\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Quero ver todos os chamados de backup que fechei esta semana, para validar se resolvi corretamente.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Finalizado\",\n",
        "                \"assunto\": \"backup\",\n",
        "                \"data_inicio\": \"2025-01-08\",\n",
        "                \"data_fim\": \"2025-01-10\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"pergunta\": \"Liste os chamados atrasados em SLA que est√£o sob minha responsabilidade.\",\n",
        "            \"filtro_body\": {\n",
        "                \"status\": \"Todos\",\n",
        "                \"sla_resposta\": \"Estourado\"\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "CxrFnzS6vknS"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C√©lula 7 - Fun√ß√£o buscar_pergunta_predefinida**"
      ],
      "metadata": {
        "id": "7T8gUy4ev5OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_pergunta_predefinida(pergunta_usuario: str, profile_type: str) -> dict:\n",
        "    \"\"\"\n",
        "    Verifica se a pergunta do usu√°rio est√° no dicion√°rio de perguntas pr√©-definidas\n",
        "    para o perfil informado. Se encontrar, retorna {'status': 'found', 'filtro_body': {...}}.\n",
        "    Caso contr√°rio, retorna {'status': 'not_found'}.\n",
        "    \"\"\"\n",
        "    perguntas_profile = perguntas_padrao_profile.get(profile_type, [])\n",
        "\n",
        "    # Simples compara√ß√£o exata (poderia ser fuzzy, caso queira expandir)\n",
        "    for item in perguntas_profile:\n",
        "        if item[\"pergunta\"].strip().lower() == pergunta_usuario.strip().lower():\n",
        "            return {\n",
        "                \"status\": \"found\",\n",
        "                \"filtro_body\": item[\"filtro_body\"]\n",
        "            }\n",
        "\n",
        "    return {\"status\": \"not_found\"}\n"
      ],
      "metadata": {
        "id": "LjFjrZpDv90Q"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C√©lula 8 - Ferramenta de Valida√ß√£o R√°pida**\n"
      ],
      "metadata": {
        "id": "_R69h5fiwHeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao_rapida_chamados(filtro_body: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Faz uma valida√ß√£o r√°pida (Tool) para verificar se existem registros.\n",
        "    Envia total_registros=1 para a API, retornando True/False ou erro.\n",
        "    Retorna:\n",
        "      {\n",
        "        \"status\": \"ok\",\n",
        "        \"tem_registros\": True/False,\n",
        "        \"erro\": None (ou string de erro)\n",
        "      }\n",
        "    \"\"\"\n",
        "    url = f\"{MILVUS_BASE_URL}/chamado/listagem\"\n",
        "    payload = {\n",
        "        \"filtro_body\": filtro_body,\n",
        "        \"total_registros\": 1\n",
        "    }\n",
        "    headers = {\n",
        "        \"Authorization\": os.getenv('MILVUS_KEY'),\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            total = data.get(\"meta\", {}).get(\"paginate\", {}).get(\"total\", 0)\n",
        "            tem_registros = (total > 0)\n",
        "            return {\"status\": \"ok\", \"tem_registros\": tem_registros, \"erro\": None}\n",
        "        else:\n",
        "            return {\"status\": \"erro\", \"tem_registros\": False, \"erro\": f\"API Error {response.status_code}: {response.text}\"}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"erro\", \"tem_registros\": False, \"erro\": str(e)}\n"
      ],
      "metadata": {
        "id": "Z5TypAXawM_y"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C√©lula 9 - Ferramentas e Fun√ß√µes Auxiliares**"
      ],
      "metadata": {
        "id": "Pzc1WYTjwYpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exibir_sugestoes_perfil(profile_type: str, pergunta_falada: str) -> str:\n",
        "    \"\"\"\n",
        "    Monta uma mensagem amig√°vel com as perguntas dispon√≠veis para aquele perfil,\n",
        "    excluindo a pergunta que falhou (se for encontrada).\n",
        "    Retorna um texto em formato de string para exibi√ß√£o ao usu√°rio.\n",
        "    \"\"\"\n",
        "    perguntas_disponiveis = []\n",
        "    for item in perguntas_padrao_profile.get(profile_type, []):\n",
        "        # Se for diferente da pergunta que acabou de falhar, lista\n",
        "        if item[\"pergunta\"].strip().lower() != pergunta_falada.strip().lower():\n",
        "            perguntas_disponiveis.append(item[\"pergunta\"])\n",
        "\n",
        "    if not perguntas_disponiveis:\n",
        "        return (\n",
        "            \"N√£o encontrei nenhum chamado para essa consulta e n√£o h√° perguntas adicionais dispon√≠veis.\\n\"\n",
        "            \"Por favor, tente reformular sua pergunta ou entre em contato com o suporte.\"\n",
        "        )\n",
        "\n",
        "    texto = (\n",
        "        \"N√£o encontrei nenhum registro para essa consulta ou ocorreu um erro.\\n\"\n",
        "        \"Estou em fase de desenvolvimento pela RJOINS.\\n\\n\"\n",
        "        \"Voc√™ pode tentar uma destas perguntas (digite o n√∫mero ou a pr√≥pria pergunta):\\n\"\n",
        "    )\n",
        "    for i, pergunta in enumerate(perguntas_disponiveis, start=1):\n",
        "        texto += f\"{i}) {pergunta}\\n\"\n",
        "    return texto\n",
        "\n",
        "def completar_filtro_por_perfil(filtro_body: Dict, profile_data: Dict, token_cliente: str | None) -> Dict:\n",
        "    \"\"\"\n",
        "    Insere campos de perfil (email_conferencia, email_tecnico, cliente_token) de acordo com o tipo do perfil.\n",
        "    Retorna uma c√≥pia atualizada do filtro_body.\n",
        "    \"\"\"\n",
        "    profile_type = profile_data.get(\"profile\")\n",
        "    valor = profile_data.get(\"value\")\n",
        "\n",
        "    # Copiamos para evitar muta√ß√µes indevidas\n",
        "    novo_filtro = dict(filtro_body)\n",
        "\n",
        "    if profile_type == \"usuario\":\n",
        "        novo_filtro[\"email_conferencia\"] = valor\n",
        "    elif profile_type == \"tecnico\":\n",
        "        novo_filtro[\"email_tecnico\"] = valor\n",
        "    elif profile_type == \"gestor\":\n",
        "        if token_cliente:\n",
        "            novo_filtro[\"cliente_token\"] = token_cliente\n",
        "        else:\n",
        "            # Se n√£o houver token, n√£o conseguimos filtrar\n",
        "            pass\n",
        "    # master n√£o precisa de nada adicional\n",
        "\n",
        "    return novo_filtro\n"
      ],
      "metadata": {
        "id": "aorGxbe3wsHs"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ü§ñ C√©lula 6 - Agente de Identifica√ß√£o de Inten√ß√£o (Router Agent) ‚úÖ (validado)"
      ],
      "metadata": {
        "id": "VQBqq19D1rmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identificar_intencao(state: dict) -> dict:\n",
        "    \"\"\"Usa o LLM para identificar a inten√ß√£o da pergunta.\"\"\"\n",
        "    ultima_mensagem = state[\"messages\"][-1]\n",
        "    pergunta = ultima_mensagem.content if isinstance(ultima_mensagem, HumanMessage) else \"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"Voc√™ √© um assistente especializado em identificar inten√ß√µes de perguntas.\n",
        "        Identifique a inten√ß√£o da pergunta do usu√°rio e responda apenas com uma das seguintes palavras-chave:\n",
        "        - listar_chamados\n",
        "        - outra_intencao\"\"\"),\n",
        "        (\"human\", \"{pergunta}\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    resposta = chain.invoke({\"pergunta\": pergunta})\n",
        "\n",
        "    state[\"intencao\"] = resposta.content.strip()\n",
        "    return state"
      ],
      "metadata": {
        "id": "BHkVQtdL1wK1",
        "collapsed": true
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß† C√©lula 7 - Agente LLM para Decidir Par√¢metros da API\n"
      ],
      "metadata": {
        "id": "Rvj4vyZv2Kqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agente_decide_filtros(state: dict) -> dict:\n",
        "    \"\"\"Usa o LLM para decidir quais campos utilizar na chamada da API.\"\"\"\n",
        "    ultima_mensagem = state[\"messages\"][-1]\n",
        "    pergunta = ultima_mensagem.content if isinstance(ultima_mensagem, HumanMessage) else \"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"Voc√™ √© um assistente especializado em extrair par√¢metros de filtro para uma API de chamados.\n",
        "        Sua fun√ß√£o √© analisar a pergunta do usu√°rio e retornar APENAS um JSON com o campo 'filtro_body' contendo os filtros necess√°rios.\n",
        "\n",
        "        Regras importantes:\n",
        "        1. Use apenas campos v√°lidos:\n",
        "           - status: para estado do chamado\n",
        "           - assunto: para busca textual\n",
        "           - prioridade: para n√≠vel de urg√™ncia\n",
        "           - data_inicio e data_fim: para filtros de per√≠odo\n",
        "           - tipo_ticket: para tipo espec√≠fico de chamado\n",
        "           - sla_resposta: para status do SLA\n",
        "           - impacto: para n√≠vel de impacto\n",
        "\n",
        "        2. Valores v√°lidos para status:\n",
        "           - \"AgAtendimento\" - aguardando atendimento\n",
        "           - \"Atendendo\" - em atendimento\n",
        "           - \"Pausado\" - pausado\n",
        "           - \"Finalizado\" - finalizado\n",
        "           - \"ChamadosAbertos\" - todos abertos\n",
        "           - \"Todos\" - todos os status\n",
        "\n",
        "        3. Se n√£o houver men√ß√£o espec√≠fica:\n",
        "           - Use \"status\": \"Todos\"\n",
        "           - Evite adicionar campos desnecess√°rios\n",
        "\n",
        "        4. Para buscas textuais:\n",
        "           - Use o campo \"assunto\" com o termo mencionado\n",
        "\n",
        "        Exemplos de respostas:\n",
        "        Para \"chamados sobre Sankhya\":\n",
        "        {{\"filtro_body\": {{\"status\": \"Todos\", \"assunto\": \"sankhya\"}}}}\n",
        "\n",
        "        Para \"chamados cr√≠ticos abertos\":\n",
        "        {{\"filtro_body\": {{\"status\": \"ChamadosAbertos\", \"prioridade\": \"Cr√≠tico\"}}}}\n",
        "\n",
        "        Para \"chamados do √∫ltimo m√™s\":\n",
        "        {{\"filtro_body\": {{\"status\": \"Todos\", \"data_inicio\": \"2025-01-01\", \"data_fim\": \"2025-01-31\"}}}}\n",
        "        \"\"\"),\n",
        "        (\"human\", \"{pergunta}\")\n",
        "    ])\n",
        "\n",
        "    # Invoca o LLM\n",
        "    chain = prompt | llm\n",
        "    resposta = chain.invoke({\"pergunta\": pergunta})\n",
        "\n",
        "    # Processa a resposta\n",
        "    resposta_texto = resposta.content.strip()\n",
        "    resposta_texto = resposta_texto.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "    try:\n",
        "        # Tenta fazer o parse do JSON\n",
        "        filtros = json.loads(resposta_texto)\n",
        "\n",
        "        # Valida√ß√µes e corre√ß√µes\n",
        "        if not isinstance(filtros, dict):\n",
        "            filtros = {\"filtro_body\": {}}\n",
        "        elif \"filtro_body\" not in filtros:\n",
        "            filtros = {\"filtro_body\": filtros}\n",
        "\n",
        "        # Garante que filtro_body existe e √© um dicion√°rio\n",
        "        if not isinstance(filtros[\"filtro_body\"], dict):\n",
        "            filtros[\"filtro_body\"] = {}\n",
        "\n",
        "        # Garante que status seja v√°lido\n",
        "        status_validos = [\n",
        "            \"AgAtendimento\", \"Atendendo\", \"Pausado\", \"Finalizado\",\n",
        "            \"ChamadosAbertos\", \"Todos\"\n",
        "        ]\n",
        "        current_status = filtros[\"filtro_body\"].get(\"status\")\n",
        "        if not current_status or current_status not in status_validos:\n",
        "            filtros[\"filtro_body\"][\"status\"] = \"Todos\"\n",
        "\n",
        "        # Remove campos vazios ou None\n",
        "        filtros[\"filtro_body\"] = {\n",
        "            k: v for k, v in filtros[\"filtro_body\"].items()\n",
        "            if v is not None and v != \"\"\n",
        "        }\n",
        "\n",
        "        state[\"filtros_api\"] = filtros\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        # Em caso de erro no JSON, usa um filtro padr√£o\n",
        "        state[\"filtros_api\"] = {\"filtro_body\": {\"status\": \"Todos\"}}\n",
        "        state[\"erro\"] = f\"Erro ao processar filtros da API: {str(e)}\"\n",
        "\n",
        "    # Debug log\n",
        "    print(\"\\n[DEBUG] Pergunta:\", pergunta)\n",
        "    print(\"[DEBUG] Filtros gerados:\", json.dumps(state[\"filtros_api\"], indent=2))\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "40vf7p4f2M-_"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testar_agente_filtros():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para testar isoladamente o agente_decide_filtros com diferentes cen√°rios\n",
        "    \"\"\"\n",
        "    # Lista de perguntas para teste\n",
        "    perguntas_teste = [\n",
        "        \"Mostre todos os chamados sobre Sankhya\",\n",
        "        \"Quais chamados est√£o abertos hoje?\",\n",
        "        \"Preciso ver os chamados cr√≠ticos\",\n",
        "        \"Liste os chamados do √∫ltimo m√™s\",\n",
        "        \"Chamados com erro de backup\",\n",
        "        \"Quero ver chamados atrasados\",\n",
        "        \"Mostre chamados de alta prioridade em atendimento\",\n",
        "        \"Chamados pausados sobre erro no sistema\",\n",
        "        \"Lista de preventivas desta semana\",\n",
        "        \"Chamados com SLA estourado\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n=== IN√çCIO DOS TESTES DO AGENTE DE FILTROS ===\\n\")\n",
        "\n",
        "    for i, pergunta in enumerate(perguntas_teste, 1):\n",
        "        print(f\"\\n--- Teste #{i} ---\")\n",
        "        print(f\"Pergunta: {pergunta}\")\n",
        "\n",
        "        # Cria um estado inicial para o teste\n",
        "        estado_teste = {\n",
        "            \"messages\": [HumanMessage(content=pergunta)],\n",
        "            \"profile\": {\"profile\": \"tecnico\", \"value\": \"teste@exemplo.com\"}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Executa o agente\n",
        "            resultado = agente_decide_filtros(estado_teste)\n",
        "\n",
        "            # Exibe o resultado formatado\n",
        "            if \"filtros_api\" in resultado:\n",
        "                print(\"\\nFiltros gerados:\")\n",
        "                print(json.dumps(resultado[\"filtros_api\"], indent=2))\n",
        "\n",
        "            if \"erro\" in resultado:\n",
        "                print(\"\\nErro encontrado:\", resultado[\"erro\"])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERRO NA EXECU√á√ÉO: {str(e)}\")\n",
        "\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "    print(\"\\n=== FIM DOS TESTES ===\")\n",
        "\n",
        "# Executar os testes\n",
        "testar_agente_filtros()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOreBZo4QE9v",
        "outputId": "73c69d87-f561-4875-dec0-5848fe0f8037"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== IN√çCIO DOS TESTES DO AGENTE DE FILTROS ===\n",
            "\n",
            "\n",
            "--- Teste #1 ---\n",
            "Pergunta: Mostre todos os chamados sobre Sankhya\n",
            "\n",
            "[DEBUG] Pergunta: Mostre todos os chamados sobre Sankhya\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"Sankhya\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"Sankhya\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #2 ---\n",
            "Pergunta: Quais chamados est√£o abertos hoje?\n",
            "\n",
            "[DEBUG] Pergunta: Quais chamados est√£o abertos hoje?\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"ChamadosAbertos\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"ChamadosAbertos\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #3 ---\n",
            "Pergunta: Preciso ver os chamados cr√≠ticos\n",
            "\n",
            "[DEBUG] Pergunta: Preciso ver os chamados cr√≠ticos\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"prioridade\": \"Cr\\u00edtico\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"prioridade\": \"Cr\\u00edtico\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #4 ---\n",
            "Pergunta: Liste os chamados do √∫ltimo m√™s\n",
            "\n",
            "[DEBUG] Pergunta: Liste os chamados do √∫ltimo m√™s\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"data_inicio\": \"2023-09-01\",\n",
            "    \"data_fim\": \"2023-09-30\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"data_inicio\": \"2023-09-01\",\n",
            "    \"data_fim\": \"2023-09-30\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #5 ---\n",
            "Pergunta: Chamados com erro de backup\n",
            "\n",
            "[DEBUG] Pergunta: Chamados com erro de backup\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"erro de backup\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"erro de backup\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #6 ---\n",
            "Pergunta: Quero ver chamados atrasados\n",
            "\n",
            "[DEBUG] Pergunta: Quero ver chamados atrasados\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"sla_resposta\": \"Atrasado\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"sla_resposta\": \"Atrasado\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #7 ---\n",
            "Pergunta: Mostre chamados de alta prioridade em atendimento\n",
            "\n",
            "[DEBUG] Pergunta: Mostre chamados de alta prioridade em atendimento\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Atendendo\",\n",
            "    \"prioridade\": \"Alta\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Atendendo\",\n",
            "    \"prioridade\": \"Alta\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #8 ---\n",
            "Pergunta: Chamados pausados sobre erro no sistema\n",
            "\n",
            "[DEBUG] Pergunta: Chamados pausados sobre erro no sistema\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Pausado\",\n",
            "    \"assunto\": \"erro no sistema\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Pausado\",\n",
            "    \"assunto\": \"erro no sistema\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #9 ---\n",
            "Pergunta: Lista de preventivas desta semana\n",
            "\n",
            "[DEBUG] Pergunta: Lista de preventivas desta semana\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"preventivas\",\n",
            "    \"data_inicio\": \"2023-10-23\",\n",
            "    \"data_fim\": \"2023-10-29\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"preventivas\",\n",
            "    \"data_inicio\": \"2023-10-23\",\n",
            "    \"data_fim\": \"2023-10-29\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Teste #10 ---\n",
            "Pergunta: Chamados com SLA estourado\n",
            "\n",
            "[DEBUG] Pergunta: Chamados com SLA estourado\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"sla_resposta\": \"Estourado\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Filtros gerados:\n",
            "{\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"sla_resposta\": \"Estourado\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "=== FIM DOS TESTES ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üõ†Ô∏è C√©lula 8 - Implementa√ß√£o da Ferramenta ChamadosAPITool\n"
      ],
      "metadata": {
        "id": "n6klwT1B19p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obter_chamados(state: dict) -> dict:\n",
        "    \"\"\"Obt√©m os chamados usando a MilvusAPI.\"\"\"\n",
        "    filtros_api = state.get(\"filtros_api\", {})\n",
        "    profile_data = state[\"profile\"]\n",
        "    profile_type = profile_data.get(\"profile\")\n",
        "\n",
        "    # Caso a LLM retorne \"filtro_body\" dentro do JSON, pegamos s√≥ esse dicion√°rio\n",
        "    if \"filtro_body\" in filtros_api:\n",
        "        filtro_body = filtros_api[\"filtro_body\"]\n",
        "    else:\n",
        "        filtro_body = filtros_api  # fallback\n",
        "\n",
        "    # Aplica dados de perfil\n",
        "    token_cliente = state.get(\"token_cliente\")\n",
        "    filtro_completo = completar_filtro_por_perfil(filtro_body, profile_data, token_cliente)\n",
        "\n",
        "    # LOG de debug\n",
        "    print(\"\\n[DEBUG] Filtro final para obter_chamados:\", filtro_completo)\n",
        "\n",
        "    # Chama a API real\n",
        "    dados_chamados = milvus_api.listar_chamados(filtro_completo)\n",
        "    print(\"[DEBUG] Retorno da API:\", dados_chamados, \"\\n\")\n",
        "\n",
        "    if \"erro\" in dados_chamados:\n",
        "        state[\"erro\"] = dados_chamados[\"erro\"]\n",
        "    else:\n",
        "        state[\"dados_chamados\"] = dados_chamados\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "Q4cPNt0u1_0a"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Interpretar a Escolha**"
      ],
      "metadata": {
        "id": "3NGyPlhaW9XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpretar_opcao_sugerida(state: dict) -> dict:\n",
        "    suggestions = state.get(\"suggestions\", [])\n",
        "    ultima_mensagem = \"\"\n",
        "    if state[\"messages\"]:\n",
        "        msg = state[\"messages\"][-1]\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            ultima_mensagem = msg.content.strip()\n",
        "\n",
        "    # Corrigido o prompt para usar chaves duplas onde necess√°rio\n",
        "    prompt_llm = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"\"\"Voc√™ √© um assistente que decide se a mensagem do usu√°rio corresponde a escolher\n",
        "         uma op√ß√£o da lista ou se √© uma pergunta nova.\n",
        "         Responda apenas em JSON, no formato:\n",
        "         {{\n",
        "           \"status\": \"selected\" ou \"new_question\",\n",
        "           \"index\": <numero ou null>,\n",
        "           \"text\": \"<texto inteiro>\"\n",
        "         }}\"\"\"),  # Note as chaves duplas aqui\n",
        "        (\"human\",\n",
        "         \"Op√ß√µes dispon√≠veis: {options}\\nUsu√°rio disse: {message}\")\n",
        "    ])\n",
        "\n",
        "    # Invoca a LLM com as vari√°veis corretas\n",
        "    chain = prompt_llm | llm\n",
        "    resposta_llm = chain.invoke({\n",
        "        \"options\": json.dumps(suggestions, ensure_ascii=False),\n",
        "        \"message\": ultima_mensagem\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        dados = json.loads(resposta_llm.content.strip())\n",
        "    except:\n",
        "        dados = {\n",
        "            \"status\": \"new_question\",\n",
        "            \"index\": None,\n",
        "            \"text\": ultima_mensagem\n",
        "        }\n",
        "\n",
        "    state[\"escolha_sugestao\"] = dados\n",
        "    return state"
      ],
      "metadata": {
        "id": "bqasgpdqW-vz"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üßÆ C√©lula 9 - Fun√ß√µes Auxiliares para Processamento de Dados\n"
      ],
      "metadata": {
        "id": "qoIY57q82Ye6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatar_resposta(state: dict) -> dict:\n",
        "    dados_chamados = state.get(\"dados_chamados\", {})\n",
        "    chamados = dados_chamados.get(\"lista\", [])\n",
        "    if not chamados:\n",
        "        state[\"resposta\"] = \"N√£o foram encontrados chamados para os crit√©rios solicitados.\"\n",
        "        return state\n",
        "\n",
        "    resposta = \"### Chamados Encontrados\\n\\n\"\n",
        "    resposta += \"| C√≥digo | Assunto | Data de Cria√ß√£o | Status |\\n\"\n",
        "    resposta += \"|--------|---------|-----------------|--------|\\n\"\n",
        "    for chamado in chamados:\n",
        "        resposta += (\n",
        "            f\"| {chamado.get('codigo', 'N/A')} \"\n",
        "            f\"| {chamado.get('assunto', 'N/A')} \"\n",
        "            f\"| {chamado.get('data_criacao', 'N/A')} \"\n",
        "            f\"| {chamado.get('status', 'N/A')} |\\n\"\n",
        "        )\n",
        "    state[\"resposta\"] = resposta\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "MqO6Qmj62Z_-"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîÑ C√©lula 10 - Configura√ß√£o do Grafo Principal\n"
      ],
      "metadata": {
        "id": "zF7loOtg49DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# C√©lula 10 - Configura√ß√£o do Grafo Principal (AJUSTADA)\n",
        "# =========================================================\n",
        "\n",
        "from typing import TypedDict, Annotated, Sequence, Dict, Union, Tuple, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "class ExtendedAgentState(TypedDict, total=False):\n",
        "    messages: Annotated[Sequence[BaseMessage], \"Mensagens da conversa\"]\n",
        "    profile: Annotated[Dict, \"Informa√ß√µes do perfil do usu√°rio\"]\n",
        "    validation_result: Annotated[bool | None, \"Resultado da valida√ß√£o\"]\n",
        "    validation_details: Annotated[Dict, \"Detalhes da valida√ß√£o\"]\n",
        "    token_cliente: Annotated[str | None, \"Token do cliente para uso posterior\"]\n",
        "    intencao: Annotated[str | None, \"Inten√ß√£o da pergunta\"]\n",
        "    filtros_api: Annotated[Dict | None, \"Filtros para a API\"]\n",
        "    dados_chamados: Annotated[Dict | None, \"Dados dos chamados\"]\n",
        "    resposta: Annotated[str | None, \"Resposta final ao usu√°rio\"]\n",
        "    erro: Annotated[str | None, \"Mensagem de erro\"]\n",
        "\n",
        "# ---------------------------------\n",
        "# 1) N√≥: validate_profile (igual antes)\n",
        "# 2) N√≥: buscar_predefinida (novo)\n",
        "# 3) N√≥: identificar_intencao (s√≥ se predefinida n√£o encontrada)\n",
        "# 4) N√≥: agente_decide_filtros (ou se foi dicion√°rio, pula)\n",
        "# 5) N√≥: validacao_rapida\n",
        "# 6) N√≥: se tem registro => obter_chamados => formatar_resposta => END\n",
        "# 7) N√≥: se n√£o tem registro ou erro => sugerir_opcoes => END (AJUSTE AQUI)\n",
        "#    (ou se quiser re-perguntar, tratar de outra forma)\n",
        "# ---------------------------------\n",
        "\n",
        "def node_buscar_predefinida(state: ExtendedAgentState) -> ExtendedAgentState:\n",
        "    \"\"\"\n",
        "    Verifica se a pergunta do usu√°rio (√∫ltima mensagem) est√° no dicion√°rio de perguntas\n",
        "    pr√©-definidas para o perfil.\n",
        "    Se encontrar, salva em state[\"filtros_api\"] e segue para valida√ß√£o r√°pida.\n",
        "    Sen√£o, segue para identificar_intencao.\n",
        "    \"\"\"\n",
        "    pergunta = \"\"\n",
        "    if state[\"messages\"]:\n",
        "        msg = state[\"messages\"][-1]\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            pergunta = msg.content\n",
        "    profile_type = state[\"profile\"].get(\"profile\", \"\")\n",
        "    resultado = buscar_pergunta_predefinida(pergunta, profile_type)\n",
        "    if resultado[\"status\"] == \"found\":\n",
        "        state[\"filtros_api\"] = {\"filtro_body\": resultado[\"filtro_body\"]}\n",
        "        # Usaremos a rota para \"validacao_rapida\"\n",
        "        state[\"intencao\"] = \"listar_chamados\"  # para padronizar o fluxo\n",
        "    else:\n",
        "        # N√£o encontrado => iremos para identificar_intencao\n",
        "        state[\"intencao\"] = None\n",
        "    return state\n",
        "\n",
        "def node_validacao_rapida(state: ExtendedAgentState) -> ExtendedAgentState:\n",
        "    \"\"\"\n",
        "    Se state[\"filtros_api\"] existir, faz uma checagem de 1 registro.\n",
        "    Se tem registro => prossegue para obter_chamados\n",
        "    Se n√£o tem => gera sugest√£o e \"erro\" = 'no_data'\n",
        "    \"\"\"\n",
        "    if not state.get(\"filtros_api\"):\n",
        "        # Se n√£o h√° filtro, n√£o h√° o que validar\n",
        "        return state\n",
        "\n",
        "    # Recupera e completa o filtro\n",
        "    profile_data = state[\"profile\"]\n",
        "    filtro_body = state[\"filtros_api\"].get(\"filtro_body\", {})\n",
        "    token_cliente = state.get(\"token_cliente\")\n",
        "    filtro_completo = completar_filtro_por_perfil(filtro_body, profile_data, token_cliente)\n",
        "\n",
        "    resultado = validacao_rapida_chamados(filtro_completo)\n",
        "    if resultado[\"status\"] == \"ok\":\n",
        "        if resultado[\"tem_registros\"]:\n",
        "            # OK, segue fluxo\n",
        "            pass\n",
        "        else:\n",
        "            # Tem status ok mas total=0 => sem registros\n",
        "            state[\"erro\"] = \"no_data\"\n",
        "    else:\n",
        "        # status=erro => erro de API\n",
        "        state[\"erro\"] = f\"Valida√ß√£o r√°pida falhou: {resultado['erro']}\"\n",
        "    return state\n",
        "\n",
        "def node_sugerir_opcoes(state: ExtendedAgentState) -> ExtendedAgentState:\n",
        "    \"\"\"\n",
        "    Gera a mensagem de sugest√£o de perguntas do dicion√°rio para o perfil,\n",
        "    e salva a lista em state[\"suggestions\"] para o pr√≥ximo passo.\n",
        "    \"\"\"\n",
        "    pergunta_falada = \"\"\n",
        "    if state[\"messages\"]:\n",
        "        msg = state[\"messages\"][-1]\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            pergunta_falada = msg.content.strip()\n",
        "\n",
        "    profile_type = state[\"profile\"].get(\"profile\", \"\")\n",
        "    perguntas_completas = perguntas_padrao_profile.get(profile_type, [])\n",
        "\n",
        "    perguntas_disponiveis = []\n",
        "    for item in perguntas_completas:\n",
        "        if item[\"pergunta\"].strip().lower() != pergunta_falada.lower():\n",
        "            perguntas_disponiveis.append(item[\"pergunta\"])\n",
        "\n",
        "    state[\"suggestions\"] = perguntas_disponiveis\n",
        "\n",
        "    if not perguntas_disponiveis:\n",
        "        texto = (\n",
        "            \"N√£o encontrei nenhum chamado para essa consulta e n√£o h√° perguntas adicionais dispon√≠veis.\\n\"\n",
        "            \"Por favor, tente reformular sua pergunta ou entre em contato com o suporte.\"\n",
        "        )\n",
        "        state[\"resposta\"] = texto\n",
        "        return state\n",
        "\n",
        "    texto = (\n",
        "        \"N√£o encontrei nenhum registro para essa consulta ou ocorreu um erro.\\n\"\n",
        "        \"Estou em fase de desenvolvimento pela RJOINS.\\n\\n\"\n",
        "        \"Voc√™ pode tentar uma destas perguntas (digite o n√∫mero ou a pr√≥pria pergunta):\\n\"\n",
        "    )\n",
        "    for i, perg_sug in enumerate(perguntas_disponiveis, start=1):\n",
        "        texto += f\"{i}) {perg_sug}\\n\"\n",
        "\n",
        "    state[\"resposta\"] = texto\n",
        "    return state\n",
        "\n",
        "def node_interpretar_opcao_sugerida(state: ExtendedAgentState) -> ExtendedAgentState:\n",
        "    \"\"\"\n",
        "    Chama a fun√ß√£o interpretar_opcao_sugerida e,\n",
        "    se for 'selected', substitui a √∫ltima mensagem do usu√°rio pela pergunta real.\n",
        "    \"\"\"\n",
        "    state = interpretar_opcao_sugerida(state)\n",
        "    escolha = state.get(\"escolha_sugestao\", {})\n",
        "    if escolha.get(\"status\") == \"selected\":\n",
        "        idx = escolha.get(\"index\") or 1\n",
        "        suggestions = state.get(\"suggestions\", [])\n",
        "        if 1 <= idx <= len(suggestions):\n",
        "            pergunta_escolhida = suggestions[idx - 1]\n",
        "            if state[\"messages\"] and isinstance(state[\"messages\"][-1], HumanMessage):\n",
        "                state[\"messages\"][-1] = HumanMessage(content=pergunta_escolhida)\n",
        "    return state\n",
        "\n",
        "def route_after_interpretar_opcao(state: ExtendedAgentState) -> str:\n",
        "    \"\"\"\n",
        "    Se o usu√°rio escolheu uma op√ß√£o, vamos para 'buscar_predefinida'.\n",
        "    Sen√£o, se for 'new_question', vamos para 'identificar_intencao'.\n",
        "    \"\"\"\n",
        "    escolha = state.get(\"escolha_sugestao\", {})\n",
        "    if escolha.get(\"status\") == \"selected\":\n",
        "        return \"buscar_predefinida\"\n",
        "    else:\n",
        "        return \"identificar_intencao\"\n",
        "\n",
        "# Montagem do grafo principal\n",
        "main_workflow = StateGraph(ExtendedAgentState)\n",
        "\n",
        "# Adicionando n√≥s\n",
        "main_workflow.add_node(\"validate_profile\", validate_profile)       # (1)\n",
        "main_workflow.add_node(\"buscar_predefinida\", node_buscar_predefinida)  # (2)\n",
        "main_workflow.add_node(\"identificar_intencao\", identificar_intencao)   # (3)\n",
        "main_workflow.add_node(\"decidir_filtros\", agente_decide_filtros)       # (4)\n",
        "main_workflow.add_node(\"validacao_rapida\", node_validacao_rapida)      # (5)\n",
        "main_workflow.add_node(\"obter_chamados\", obter_chamados)               # (6)\n",
        "main_workflow.add_node(\"formatar_resposta\", formatar_resposta)\n",
        "main_workflow.add_node(\"sugerir_opcoes\", node_sugerir_opcoes)\n",
        "\n",
        "# Entry point\n",
        "main_workflow.set_entry_point(\"validate_profile\")\n",
        "\n",
        "# 1) validate_profile -> se validation_result True => buscar_predefinida, sen√£o END\n",
        "def route_after_validate(state: ExtendedAgentState) -> str:\n",
        "    if state.get(\"validation_result\"):\n",
        "        return \"buscar_predefinida\"\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "main_workflow.add_conditional_edges(\"validate_profile\", route_after_validate)\n",
        "\n",
        "# 2) buscar_predefinida -> se intencao= \"listar_chamados\" => validacao_rapida, sen√£o identificar_intencao\n",
        "def route_after_buscar_predefinida(state: ExtendedAgentState) -> str:\n",
        "    if state.get(\"intencao\") == \"listar_chamados\":\n",
        "        return \"validacao_rapida\"\n",
        "    else:\n",
        "        return \"identificar_intencao\"\n",
        "\n",
        "main_workflow.add_conditional_edges(\"buscar_predefinida\", route_after_buscar_predefinida)\n",
        "\n",
        "# 3) identificar_intencao -> se \"listar_chamados\" => decidir_filtros, else END\n",
        "def route_after_intencao(state: ExtendedAgentState) -> str:\n",
        "    if state.get(\"intencao\") == \"listar_chamados\":\n",
        "        return \"decidir_filtros\"\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "main_workflow.add_conditional_edges(\"identificar_intencao\", route_after_intencao)\n",
        "\n",
        "# 4) decidir_filtros -> validacao_rapida\n",
        "main_workflow.add_edge(\"decidir_filtros\", \"validacao_rapida\")\n",
        "\n",
        "# 5) validacao_rapida -> se erro is None => obter_chamados, sen√£o sugerir_opcoes\n",
        "def route_after_validacao_rapida(state: ExtendedAgentState) -> str:\n",
        "    if state.get(\"erro\"):\n",
        "        return \"sugerir_opcoes\"\n",
        "    else:\n",
        "        return \"obter_chamados\"\n",
        "\n",
        "main_workflow.add_conditional_edges(\"validacao_rapida\", route_after_validacao_rapida)\n",
        "\n",
        "# 6) obter_chamados -> formatar_resposta\n",
        "main_workflow.add_edge(\"obter_chamados\", \"formatar_resposta\")\n",
        "\n",
        "# 7) formatar_resposta -> END\n",
        "main_workflow.add_edge(\"formatar_resposta\", END)\n",
        "\n",
        "# ------------------------------------\n",
        "# AJUSTE AQUI PARA EVITAR LOOP INFINITO\n",
        "# ------------------------------------\n",
        "# Antes: main_workflow.add_edge(\"sugerir_opcoes\", \"interpretar_opcao_sugerida\")\n",
        "# Substitu√≠mos pela linha abaixo para encerrar o fluxo diretamente:\n",
        "main_workflow.add_edge(\"sugerir_opcoes\", END)\n",
        "# ------------------------------------\n",
        "\n",
        "# Se voc√™ quiser manter a l√≥gica de interpretar escolha, basta comentar a linha acima,\n",
        "# reativar a antiga e ter algum crit√©rio adicional para n√£o cair no loop.\n",
        "\n",
        "main_workflow.add_node(\"interpretar_opcao_sugerida\", node_interpretar_opcao_sugerida)\n",
        "main_workflow.add_conditional_edges(\"interpretar_opcao_sugerida\", route_after_interpretar_opcao)\n",
        "\n",
        "# Compila o grafo final\n",
        "agent_graph = main_workflow.compile()\n"
      ],
      "metadata": {
        "id": "J7G4Wxwr4_2Q"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üìù C√©lula 11 - Fluxo Principal de Execu√ß√£o\n"
      ],
      "metadata": {
        "id": "tprdIe9V2mtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fluxo_principal(profile_usuario, pergunta_usuario):\n",
        "    try:\n",
        "        # Configura√ß√£o inicial do estado\n",
        "        initial_state = {\n",
        "            \"messages\": [HumanMessage(content=pergunta_usuario)],\n",
        "            \"profile\": profile_usuario,\n",
        "            \"validation_result\": None,\n",
        "            \"validation_details\": {},\n",
        "            \"token_cliente\": None\n",
        "        }\n",
        "\n",
        "        # Executa o grafo com o estado inicial\n",
        "        result = agent_graph.invoke(initial_state)\n",
        "\n",
        "        # Exibe a resposta formatada\n",
        "        if \"resposta\" in result:\n",
        "            print(result[\"resposta\"])\n",
        "        elif \"erro\" in result:\n",
        "            print(f\"Erro: {result['erro']}\")\n",
        "        else:\n",
        "            print(\"Nenhuma resposta ou erro encontrado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na execu√ß√£o: {e}\")"
      ],
      "metadata": {
        "id": "5pr9JSe52qht"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß™ C√©lula 12 - Testando o Fluxo com Diferentes Perfis\n"
      ],
      "metadata": {
        "id": "872iVG4miVyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste 1: Pergunta pr√©-definida do usu√°rio\n",
        "profile_usuario = {\n",
        "    \"profile\": \"usuario\",\n",
        "    \"value\": \"lais.castro@pailon.com.br\"\n",
        "}\n",
        "pergunta_usuario = \"Quais chamados com assunto Lobolo?\"\n",
        "\n",
        "print(\"=== Teste 1: Pergunta pr√©-definida do usu√°rio ===\")\n",
        "fluxo_principal(profile_usuario, pergunta_usuario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mma70CT2-Nn",
        "outputId": "69756c25-f53d-48da-9416-dabdeb3d2096"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Teste 1: Pergunta pr√©-definida do usu√°rio ===\n",
            "\n",
            "[DEBUG] Pergunta: Quais chamados com assunto Lobolo?\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"Lobolo\"\n",
            "  }\n",
            "}\n",
            "N√£o encontrei nenhum registro para essa consulta ou ocorreu um erro.\n",
            "Estou em fase de desenvolvimento pela RJOINS.\n",
            "\n",
            "Voc√™ pode tentar uma destas perguntas (digite o n√∫mero ou a pr√≥pria pergunta):\n",
            "1) Quais chamados eu tenho em aberto agora?\n",
            "2) Mostre meus chamados finalizados nos √∫ltimos 30 dias, por favor.\n",
            "3) Preciso ver meu hist√≥rico de chamados sobre erro paytrack e configura√ß√µes, para comparar.\n",
            "4) Quero saber quais chamados est√£o com SLA estourado, pois ainda n√£o fui atendido.\n",
            "5) Liste meus chamados com prioridade alta e me informe se j√° foram respondidos.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZG6nsuG02Xdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# C√âLULA NOVA: Loop de Conversa\n",
        "# =========================================\n",
        "def iniciar_conversa(profile_usuario: dict):\n",
        "    \"\"\"\n",
        "    Exemplo de loop que mant√©m o estado da conversa.\n",
        "    O usu√°rio digita repetidamente e podemos seguir com as sugest√µes.\n",
        "    \"\"\"\n",
        "    # Montamos o estado inicial\n",
        "    state: ExtendedAgentState = {\n",
        "        \"messages\": [],\n",
        "        \"profile\": profile_usuario,\n",
        "        \"validation_result\": None,\n",
        "        \"validation_details\": {},\n",
        "        \"token_cliente\": None\n",
        "    }\n",
        "\n",
        "    print(\"Digite 'sair' para encerrar.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"Voc√™: \")\n",
        "        if not user_input or user_input.strip().lower() == \"sair\":\n",
        "            print(\"Encerrando conversa.\")\n",
        "            break\n",
        "\n",
        "        # Adiciona a nova mensagem do usu√°rio\n",
        "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        # Processa no grafo\n",
        "        state = agent_graph.invoke(state)\n",
        "\n",
        "        # Exibe resposta do assistente\n",
        "        resposta = state.get(\"resposta\", \"\")\n",
        "        if resposta:\n",
        "            print(f\"Assistente: {resposta}\")\n",
        "        elif state.get(\"erro\"):\n",
        "            print(f\"Assistente (ERRO): {state['erro']}\")\n",
        "        else:\n",
        "            print(\"Assistente: (sem resposta)\")\n",
        "\n",
        "        # Se quiser checar se finalizamos o grafo:\n",
        "        # if state.get(\"__graph_state__\") == \"END\":\n",
        "        #     print(\"Fluxo chegou ao END. Podemos continuar ou encerrar.\\n\")\n",
        "        #     # break\n"
      ],
      "metadata": {
        "id": "pVVfN0qZaGsY"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_usuario = {\"profile\": \"usuario\", \"value\": \"lais.castro@pailon.com.br\"}\n",
        "iniciar_conversa(profile_usuario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "KC70IPWvaY4w",
        "outputId": "984c1751-ecc8-4232-eb50-2e18021e6ad0"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite 'sair' para encerrar.\n",
            "\n",
            "Voc√™: Quantos chamados tenho com asssunto backup?\n",
            "\n",
            "[DEBUG] Pergunta: Quantos chamados tenho com asssunto backup?\n",
            "[DEBUG] Filtros gerados: {\n",
            "  \"filtro_body\": {\n",
            "    \"status\": \"Todos\",\n",
            "    \"assunto\": \"backup\"\n",
            "  }\n",
            "}\n",
            "Assistente: N√£o encontrei nenhum registro para essa consulta ou ocorreu um erro.\n",
            "Estou em fase de desenvolvimento pela RJOINS.\n",
            "\n",
            "Voc√™ pode tentar uma destas perguntas (digite o n√∫mero ou a pr√≥pria pergunta):\n",
            "1) Quais chamados eu tenho em aberto agora?\n",
            "2) Mostre meus chamados finalizados nos √∫ltimos 30 dias, por favor.\n",
            "3) Preciso ver meu hist√≥rico de chamados sobre erro paytrack e configura√ß√µes, para comparar.\n",
            "4) Quero saber quais chamados est√£o com SLA estourado, pois ainda n√£o fui atendido.\n",
            "5) Liste meus chamados com prioridade alta e me informe se j√° foram respondidos.\n",
            "\n",
            "Voc√™: 1\n",
            "Assistente: N√£o encontrei nenhum registro para essa consulta ou ocorreu um erro.\n",
            "Estou em fase de desenvolvimento pela RJOINS.\n",
            "\n",
            "Voc√™ pode tentar uma destas perguntas (digite o n√∫mero ou a pr√≥pria pergunta):\n",
            "1) Quais chamados eu tenho em aberto agora?\n",
            "2) Mostre meus chamados finalizados nos √∫ltimos 30 dias, por favor.\n",
            "3) Preciso ver meu hist√≥rico de chamados sobre erro paytrack e configura√ß√µes, para comparar.\n",
            "4) Quero saber quais chamados est√£o com SLA estourado, pois ainda n√£o fui atendido.\n",
            "5) Liste meus chamados com prioridade alta e me informe se j√° foram respondidos.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-257-5cb9fea5bf91>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprofile_usuario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"profile\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"usuario\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"lais.castro@pailon.com.br\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miniciar_conversa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_usuario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-256-525c386ac768>\u001b[0m in \u001b[0;36miniciar_conversa\u001b[0;34m(profile_usuario)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Digite 'sair' para encerrar.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Voc√™: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sair\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encerrando conversa.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}